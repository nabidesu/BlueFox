{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "import statistics\n",
        "\n",
        "#  Define a long simulated text\n",
        "sample_text = (\"My name is Apekshya. I study in islington college. \" * 50) * 10\n",
        "\n",
        "#Set chunk size and overlap combinations\\\n",
        "chunk_configs = [\n",
        "    (300, 50),\n",
        "    (500, 100),\n",
        "    (1000, 200),\n",
        "    (2000, 400)\n",
        "]\n"
      ],
      "metadata": {
        "id": "IANPJ0zq0qwS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Experimenting with sample text:\")\n",
        "for chunk_size, overlap in chunk_configs:\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "    chunks = splitter.split_text(sample_text)\n",
        "    lengths = [len(chunk) for chunk in chunks]\n",
        "\n",
        "    print(f\"\\n--- Chunk Size: {chunk_size}, Overlap: {overlap} ---\")\n",
        "    print(f\" Total Chunks: {len(chunks)}\")\n",
        "    print(f\" Avg Length: {statistics.mean(lengths):.2f} characters\")\n",
        "    print(f\" First Chunk Preview:\\n{chunks[0][:300]}...\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnu4u-XzENLz",
        "outputId": "2f9dade7-34b9-443b-a888-2efff2dcbeb4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Experimenting with sample text:\n",
            "\n",
            "--- Chunk Size: 300, Overlap: 50 ---\n",
            " Total Chunks: 100\n",
            " Avg Length: 295.58 characters\n",
            " First Chunk Preview:\n",
            "My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington...\n",
            "\n",
            "\n",
            "--- Chunk Size: 500, Overlap: 100 ---\n",
            " Total Chunks: 63\n",
            " Avg Length: 494.32 characters\n",
            " First Chunk Preview:\n",
            "My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington col...\n",
            "\n",
            "\n",
            "--- Chunk Size: 1000, Overlap: 200 ---\n",
            " Total Chunks: 32\n",
            " Avg Length: 984.00 characters\n",
            " First Chunk Preview:\n",
            "My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington col...\n",
            "\n",
            "\n",
            "--- Chunk Size: 2000, Overlap: 400 ---\n",
            " Total Chunks: 16\n",
            " Avg Length: 1966.50 characters\n",
            " First Chunk Preview:\n",
            "My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington college. My name is Apekshya. I study in islington col...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    CharacterTextSplitter,\n",
        "    TokenTextSplitter,\n",
        "    NLTKTextSplitter\n",
        ")\n",
        "import statistics\n",
        "\n",
        "# Sample text\n",
        "sample_text = (\"Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. \" * 50) * 10\n",
        "\n",
        "\n",
        "chunk_size = 500\n",
        "chunk_overlap = 100\n"
      ],
      "metadata": {
        "id": "UNXBxC8VD3HT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTBVXuPOEo8N",
        "outputId": "0dfb35f0-5928-400e-c60d-4c6a285e0d7b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize different splitters\n",
        "splitters = {\n",
        "    \"RecursiveCharacterTextSplitter\": RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    ),\n",
        "    \"CharacterTextSplitter\": CharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    ),\n",
        "    \"TokenTextSplitter\": TokenTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    ),\n",
        "    \"NLTKTextSplitter\": NLTKTextSplitter()\n",
        "}"
      ],
      "metadata": {
        "id": "_YnrFNIiES5S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Comparing Different Text Splitters:\\n\")\n",
        "\n",
        "for name, splitter in splitters.items():\n",
        "    try:\n",
        "        chunks = splitter.split_text(sample_text)\n",
        "        lengths = [len(chunk) for chunk in chunks]\n",
        "\n",
        "        print(f\"\\n=== {name} ===\")\n",
        "        print(f\"Total Chunks: {len(chunks)}\")\n",
        "        print(f\" Avg Length: {statistics.mean(lengths):.2f} characters\")\n",
        "        print(f\" First Chunk Preview:\\n{chunks[0][:300]}...\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n {name} failed with error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwCFOnHSEgIu",
        "outputId": "27adb29b-76fa-4b17-ab74-f9383f666a68"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing Different Text Splitters:\n",
            "\n",
            "\n",
            "=== RecursiveCharacterTextSplitter ===\n",
            "Total Chunks: 116\n",
            " Avg Length: 493.71 characters\n",
            " First Chunk Preview:\n",
            "Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope y...\n",
            "\n",
            "\n",
            "=== CharacterTextSplitter ===\n",
            "Total Chunks: 1\n",
            " Avg Length: 45999.00 characters\n",
            " First Chunk Preview:\n",
            "Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope y...\n",
            "\n",
            "\n",
            "=== TokenTextSplitter ===\n",
            "Total Chunks: 33\n",
            " Avg Length: 1736.88 characters\n",
            " First Chunk Preview:\n",
            "Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope you are fine. i am good as well. i have started living in Kathmandu. Hi how are you. I hope y...\n",
            "\n",
            "\n",
            "=== NLTKTextSplitter ===\n",
            "Total Chunks: 13\n",
            " Avg Length: 3867.54 characters\n",
            " First Chunk Preview:\n",
            "Hi how are you.\n",
            "\n",
            "I hope you are fine.\n",
            "\n",
            "i am good as well.\n",
            "\n",
            "i have started living in Kathmandu.\n",
            "\n",
            "Hi how are you.\n",
            "\n",
            "I hope you are fine.\n",
            "\n",
            "i am good as well.\n",
            "\n",
            "i have started living in Kathmandu.\n",
            "\n",
            "Hi how are you.\n",
            "\n",
            "I hope you are fine.\n",
            "\n",
            "i am good as well.\n",
            "\n",
            "i have started living in Kathmandu.\n",
            "\n",
            "Hi how are y...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured\n",
        "\n",
        "from langchain_community.document_loaders import (\n",
        "    PyPDFLoader,\n",
        "    TextLoader,\n",
        "    CSVLoader,\n",
        "    UnstructuredFileLoader,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKyyNK4_I0Bn",
        "outputId": "0f435ad5-4727-4987-970a-d060bc3f2de6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.4)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.0.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.35.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2025.4.26)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (2.11.4)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (5.5.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Downloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.35.0-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=0d06f852db2f9a4e10864c7d1ee984577f2f77f2872904702dd04e316e19fb40\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, olefile, langdetect, emoji, backoff, aiofiles, python-oxmsg, unstructured-client, unstructured\n",
            "Successfully installed aiofiles-24.1.0 backoff-2.2.1 emoji-2.14.1 filetype-1.2.0 langdetect-1.0.9 olefile-0.47 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 unstructured-0.17.2 unstructured-client-0.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = {\n",
        "    \"TextLoader\": (\"example.txt\", TextLoader),\n",
        "    \"PyPDFLoader\": (\"drylab.pdf\", PyPDFLoader),\n",
        "    \"CSVLoader\": (\"text.csv\", CSVLoader),\n",
        "    \"UnstructuredFileLoader\": (\"about.html\", UnstructuredFileLoader),  # works for .docx, .pdf, etc. too\n",
        "}"
      ],
      "metadata": {
        "id": "mgZjdZpxI7Db"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, (path, LoaderClass) in loaders.items():\n",
        "    try:\n",
        "        loader = LoaderClass(path)\n",
        "        docs = loader.load()\n",
        "        print(f\"\\n {name} loaded {len(docs)} document(s) from {path}\")\n",
        "        print(f\"First 300 chars:\\n{docs[0].page_content[:300]}...\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n {name} failed to load {path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMKdaCqSJlYs",
        "outputId": "97e8bf30-207e-4001-95ce-703a7b739b86"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TextLoader failed to load example.txt: Error loading example.txt\n",
            "\n",
            " PyPDFLoader loaded 3 document(s) from drylab.pdf\n",
            "First 300 chars:\n",
            "DrylabNewsfor investors & friends · Ma y 2017\n",
            "Welcome to our first newsletter of 2017! It's\n",
            "been a while since the last one, and a lot has\n",
            "happened. We promise to keep them coming\n",
            "every two months hereafter, and permit\n",
            "ourselves to make this one rather long. The\n",
            "big news is the beginnings of our lau...\n",
            "\n",
            "\n",
            " CSVLoader loaded 416809 document(s) from text.csv\n",
            "First 300 chars:\n",
            "tweet_id: 0\n",
            "content: i just feel really helpless and heavy hearted\n",
            "sentiment: 4...\n",
            "\n",
            "\n",
            " UnstructuredFileLoader loaded 1 document(s) from about.html\n",
            "First 300 chars:\n",
            "Meet The Team\n",
            "\n",
            "\n",
            "\n",
            "Rushav\n",
            "\n",
            "\n",
            "\n",
            "Sulav\n",
            "\n",
            "\n",
            "\n",
            "Hari...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}